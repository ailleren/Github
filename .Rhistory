install.packages('rpart.plot')
library(partykit)
library(rpart.plot)
options(repos = c(CRAN = "http://cran.rstudio.com"))
install.packages('partykit')
options(repos = c(CRAN = "http://cran.rstudio.com"))
options(repos = c(CRAN = "http://cran.rstudio.com"))
install.packages('partykit')
options(repos = c(CRAN = "http://cran.rstudio.com"))
install.packages('partykit')
source('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/load_libraries.R')
source('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/f_partition.R')
source('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/regression_metrics.R')
whole_data<-f_partition(df=fread('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/data_automobile_ready.csv'),
test_proportion = 0.2,
seed = 872367823)
str(whole_data)
whole_data<-lapply(whole_data, function(x){
return(x[, which(sapply(x, is.integer)):=lapply(.SD, as.numeric), .SDcols=sapply(x,is.integer)])
})
str(whole_data)
# we start defining a formula
formula<-as.formula(price~.)   # price against all other variables
install.packages('partykit')
install.packages('partykit', repos = "https://cran.rstudio.com")
install.packages('rpart.plot')
install.packages('rpart.plot')
# ML for continuous target variable
# 1. Tree Based Models
# 2. Regression
source('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/load_libraries.R')
source('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/f_partition.R')
source('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/regression_metrics.R')
whole_data<-f_partition(df=fread('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/data_automobile_ready.csv'),
test_proportion = 0.2,
seed = 872367823)
str(whole_data)
whole_data<-lapply(whole_data, function(x){
return(x[, which(sapply(x, is.integer)):=lapply(.SD, as.numeric), .SDcols=sapply(x,is.integer)])
})
str(whole_data)
# we start defining a formula
formula<-as.formula(price~.)
install.packages('partykit')
# ML for continuous target variable
# 1. Tree Based Models
# 2. Regression
source('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/load_libraries.R')
source('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/f_partition.R')
source('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/regression_metrics.R')
whole_data<-f_partition(df=fread('/Users/ailleren/Documents/IE\ -\ MBD/3rd\ Term/Advanced\ R/data_automobile_ready.csv'),
test_proportion = 0.2,
seed = 872367823)
str(whole_data)
whole_data<-lapply(whole_data, function(x){
return(x[, which(sapply(x, is.integer)):=lapply(.SD, as.numeric), .SDcols=sapply(x,is.integer)])
})
str(whole_data)
# we start defining a formula
formula<-as.formula(price~.)
install.packages('partykit')
library(rpart.plot)
install.packages('rpart.plot')
library(rpart.plot)
library(partykit)
tree_0<-rpart(formula = formula, data = whole_data$train, method = 'anova', model=TRUE)
print(as.party(tree_0))
rpart.plot(tree_0, digits = 4,type = 2,box.palette = 'Gn')
test_tree<-predict(tree_0, newdata = whole_data$test,type = 'vector')
df_pred<-whole_data$test[, .(id=1:.N,price, test_tree)]
str(df_pred)
ggplot(melt(df_pred, id.vars = 'id'), aes(x=id,y=value, colour=variable))+
geom_point(alpha=0.65)+geom_line(alpha=0.65)+
ylim(0,50000)+xlab('')+ylab('$')+
ggtitle('Regression Tree - Test Prediction on Automobile Price')+
scale_colour_manual(values = c('black','red'))
rmse_tree<-rmse(real=whole_data$test$price, predicted = test_tree)
mae_tree<-mae(real=whole_data$test$price, predicted = test_tree)
mape_tree<-mape(real=whole_data$test$price, predicted = test_tree)
mape_tree
# another type of partitioning trees, based on conditional inference tests
ctree_0<-ctree(formula, data = whole_data$train)
print(ctree_0)
plot(ctree_0)
#### 1.2 Random Forest
library(randomForest)
rf_0<-randomForest(formula=formula, data=whole_data$train)
print(rf_0)
test_rf<-predict(rf_0, newdata = whole_data$test, type='response')
df_pred<-cbind(df_pred, test_rf)
str(df_pred)
ggplot(melt(df_pred, id.vars = 'id'), aes(x=id,y=value, colour=variable))+
geom_point(alpha=0.65)+geom_line(alpha=0.65)+
ylim(0,50000)+xlab('')+ylab('$')+
ggtitle('Random Forest - Test Prediction on Automobile Price')+
scale_colour_manual(values = c('black','red','blue'))
rmse_rf<-rmse(real=whole_data$test$price, predicted = test_rf)
mae_rf<-mae(real=whole_data$test$price, predicted = test_rf)
mape_rf<-mape(real=whole_data$test$price, predicted = test_rf)
mape_rf
library(ranger)
rf_1<-ranger(formula, whole_data$train)
test_rf1<-predict(rf_1,whole_data$test)$predictions
mape(real=whole_data$test$price, predicted = test_rf1)
qplot(test_rf, test_rf1)
#### 1.3 Boosting Tree
library(xgboost)
xgb_0<-xgboost(booster='gbtree',
data=as.matrix(whole_data$train[, !'price', with=F]),
label=whole_data$train$price,
nrounds = 50,
objective='reg:linear')
print(xgb_0)
test_xgb<-predict(xgb_0, newdata = as.matrix(whole_data$test[, !'price', with=F]), type='response')
df_pred<-cbind(df_pred, test_xgb)
str(df_pred)
ggplot(melt(df_pred, id.vars = 'id'), aes(x=id,y=value, colour=variable))+
geom_point(alpha=0.65)+geom_line(alpha=0.65)+
ylim(0,50000)+xlab('')+ylab('$')+
ggtitle('Boosted Tree - Test Prediction on Automobile Price')+
scale_colour_manual(values = c('black','red','blue','forestgreen'))
rmse_xgb<-rmse(real=whole_data$test$price, predicted = test_xgb)
mae_xgb<-mae(real=whole_data$test$price, predicted = test_xgb)
mape_xgb<-mape(real=whole_data$test$price, predicted = test_xgb)
mape_xgb
#### 2.1 Regression with StepWise feature selection
library(MASS)
lm_0<-stepAIC(lm(formula = formula,
data=whole_data$train),
trace=F)
summary(lm_0)
summary(stepAIC(lm(formula = formula,
data=data.frame(scale(whole_data$train))),
trace=F))
test_lm<-predict(lm_0, newdata = whole_data$test)
df_pred<-cbind(df_pred, test_lm)
str(df_pred)
ggplot(melt(df_pred, id.vars = 'id'), aes(x=id,y=value, colour=variable))+
geom_point(alpha=0.65)+geom_line(alpha=0.65)+
ylim(0,50000)+xlab('')+ylab('$')+
ggtitle('Linear Regression - Test Prediction on Automobile Price')+
scale_colour_manual(values = c('black','red','blue','forestgreen','orange'))
knitr::opts_chunk$set(echo = TRUE)
packages_list <- c('ggplot2',
'dplyr',
'Amelia',
'caret',
'corrplot',
'ranger',
'data.table'
)
for (i in packages_list){
if(!i%in%installed.packages()){
install.packages(i, dependencies = TRUE)
library(i, character.only = TRUE)
print(paste0(i, ' has been installed'))
} else {
print(paste0(i, ' is already installed'))
library(i, character.only = TRUE)
}
}
BarFillColor <- "#330066"
HBarFillColor <- "#000099"
BarLineColor <- "#FFFAFA"
MissingColor <- "#FF6666"
mape<-function(real,predicted){
return(mean(abs((real-predicted)/real)))
}
outlier_treatment <- function(input) {
x <- input
qnt <- quantile(x, probs=c(.25, .75), na.rm = T)
caps <- quantile(x, probs=c(.05, .95), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
x[x < (qnt[1] - H)] <- caps[1]
x[x > (qnt[2] + H)] <- caps[2]
return(x)
}
PlotImportance = function(importance)
{
varImportance <- data.frame(Variables = row.names(importance[[1]]),
Importance = round(importance[[1]]$Overall,2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
rankImportancefull = rankImportance
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance)) +
geom_bar(stat='identity',colour="white", fill = BarFillColor) +
geom_text(aes(x = Variables, y = 1, label = Rank),
hjust=0, vjust=.5, size = 4, colour = 'black',
fontface = 'bold') +
labs(x = 'Variables', title = 'Relative Variable Importance') +
coord_flip() +
theme_bw()
}
house_price <- read.csv('input/house_price_train.csv', stringsAsFactor=F)
#house_test <- read.csv('input/house_price_test.csv', stringsAsFactor=F)
str(house_price)
summary(house_price)
sum(duplicated(house_price$id))
#Converting 'date' to Date type. A variable 'date2' is temporary created
house_price$date2 <- as.Date(house_price$date, "%m/%d/%Y")
#Order observations by decreasing 'id' and 'date2'
temp<-house_price[order(house_price$id, house_price$date2,decreasing = T),]
#Id duplicates are removed
temp <- temp[!duplicated(temp$id),]
#Duplicate IDs are no longer present
sum(duplicated(temp$id))
#Discard ID and date as they will not be used in the model
house_price <- temp #17173 observations
house_price$id <- NULL
house_price$date <- NULL
house_price$date2 <- NULL
numcols <- select_if(house_price, is.numeric)
missmap(numcols, y.labels = NULL, y.at = NULL,
main = 'Missing values per Numeric variable', rank.order = TRUE,
col = c(MissingColor, HBarFillColor)) #No missing values in Numeric variables
catcols <- c("waterfront","yr_built","yr_renovated","zipcode")
house_price[,catcols] <- data.frame(apply(house_price[catcols], 2, as.factor))
missmap(house_price[,catcols], y.labels = NULL, y.at = NULL,
main = 'Missing values per Categorical variable', rank.order = TRUE,
col = c(MissingColor, HBarFillColor)) #No missing values in Categorical variables
set.seed(1234)
index <- createDataPartition(house_price$waterfront,p=0.8,list=FALSE)
#Split dataset in Train (80%) and Test (20%)
house_train <- house_price[index,]
house_test <- house_price[-index,]
#kfolds
kfolds <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
#Train baseline model
baseline_model <- train(price~.,data=house_train, method="lm", trControl = kfolds)
#Print Model Results
print(baseline_model)
#Baseline Model predictions
val_baseline <- predict(baseline_model,house_test)
paste("MAPE: ", mape(real=house_test$price, predicted = val_baseline)*100,"%",sep = '')
qplot(house_test$price, val_baseline)
par(mfrow=c(2,5))
for(i in 1:ncol(numcols)) {
boxplot(numcols[,i], main=names(numcols)[i])
}
house_price$bedrooms_t <- outlier_treatment(house_price$bedrooms)
house_price$bathrooms_t <- outlier_treatment(house_price$bathrooms)
house_price$sqft_living_t <- outlier_treatment(house_price$sqft_living)
house_price$sqft_lot_t <- outlier_treatment(house_price$sqft_lot)
house_price$sqft_above_t <- outlier_treatment(house_price$sqft_above)
house_price$sqft_living15_t <- outlier_treatment(house_price$sqft_living15)
house_price$sqft_lot15_t <- outlier_treatment(house_price$sqft_lot15)
house_price$grade_t <- outlier_treatment(house_price$grade)
house_price$basement <- ifelse(house_price$sqft_basement == 0, 0, 1)
house_price$fview <- ifelse(house_price$view == 0, 0, 1)
par(mfrow=c(2,2))
for(i in 1:length(catcols)) {
counts <- table(house_price[,catcols][,i])
name <- names(house_price[,catcols])[i]
barplot(counts, main=name)
}
house_price$renovated <- ifelse(house_price$yr_renovated == 0, 0, 1)
house_price$houseAge <- as.integer(format(Sys.Date(), "%Y")) - as.integer(as.character(house_price$yr_built))
catcols <- c(catcols,"fview","renovated", "basement")
house_price[,catcols] <- data.frame(apply(house_price[catcols], 2, as.factor))
rm_col <- c("bedrooms","bathrooms","sqft_living","sqft_lot","sqft_above",
"sqft_basement","sqft_living15",
"sqft_lot15","grade","view")
house_price1 <- house_price[, !(colnames(house_price) %in% rm_col), drop = FALSE]
numcols <- select_if(house_price1, is.numeric)
par(mfrow=c(2,4))
for(i in 1:ncol(numcols)) {
boxplot(numcols[,i], main=names(numcols)[i])
}
par(mfrow=c(2,4))
for(i in 1:length(catcols)) {
counts <- table(house_price1[,catcols][,i])
name <- names(house_price1[,catcols])[i]
barplot(counts, main=name)
}
#Select all variables minus Target variable
house_price2 <- subset(house_price1, select = -c(price))
#Plot Correlation Matrix
CorrelationResults <- cor(select_if(house_price2, is.numeric))
corrplot(CorrelationResults,method="color", type='upper',addCoef.col = "black",
number.cex = 0.5, tl.col = "black", tl.cex = 0.7, cl.cex = 0.7)
house_price1$sqft_living_tf <- scale(house_price1$sqft_living_t)
house_price1$sqft_lot_tf <- scale(house_price1$sqft_lot_t)
house_price1$houseAge_f <- scale(house_price1$houseAge)
house_price1$bathrooms_tf <- scale(house_price1$bathrooms_t)
house_price1$bedrooms_tf <- scale(house_price1$bedrooms_t)
house_price1$floors_f <- scale(house_price1$floors)
house_price1$condition_f <- scale(house_price1$condition)
house_price1$grade_tf <- scale(house_price1$grade_t)
keep_col <- c("price","grade_tf","sqft_living_tf","sqft_lot_tf","renovated",
"basement","houseAge_f","bathrooms_tf","bedrooms_tf","floors_f",
"waterfront","fview","lat", "long","condition_f")
house_price3 <- house_price1[, (colnames(house_price1) %in% keep_col)]
house_train3 <- house_price3[index,]
house_test3 <- house_price3[-index,]
model_lm <- train(price~.,data=house_train3, method="lm", trControl = kfolds)
print(model_lm)
# Prediction
val_lm <- predict(model_lm,house_test3)
paste("MAPE: ", mape(real=house_test3$price, predicted = val_lm)*100,"%",sep = '')
qplot(house_test3$price, val_lm)
# Define grid of hyperparameters to tune
tuneGrid=data.table(expand.grid(mtry=c(5,14),
splitrule='variance',
min.node.size=c(2,5,10)))
model_rf <- train(price~.,data=house_train3, method="ranger",
num.trees=500,
preProc = NULL,
tuneGrid = tuneGrid,
trControl = kfolds,
metric = "MAE")
print(model_rf)
# Prediction
val_rf <- predict(model_rf,house_test3)
paste("MAPE: ", mape(real=house_test3$price, predicted = val_rf)*100,"%",sep = '')
qplot(house_test3$price, val_rf)
model_gbm <- train(price~.,data=house_train3, method="gbm",
trControl = kfolds,
verbose = F)
print(model_gbm)
# Prediction
val_gbm <- predict(model_gbm,house_test3)
paste("MAPE: ", mape(real=house_test3$price, predicted = val_gbm)*100,"%",sep = '')
qplot(house_test3$price, val_gbm)
xgbGrid <- expand.grid(nrounds = 500,
max_depth = 4,
eta = .05,
gamma = 0,
colsample_bytree = .5,
min_child_weight = 1,
subsample = 1)
model_xgb<- train(price~.,data=house_train3, method="xgbTree", trControl=kfolds,
tuneGrid = xgbGrid, na.action = na.pass,
metric = "MAE")
print(model_xgb)
# Prediction
val_xgb <- predict(model_xgb,house_test3)
paste("MAPE: ", mape(real=house_test3$price, predicted = val_xgb)*100,"%",sep = '')
qplot(house_test3$price, val_xgb)
# Principal Components Analysis
PCAData = house_price3 %>%
select(lat,long)
pca = prcomp(PCAData, scale. = T)
pca_temp <- predict(pca, newdata = PCAData)
pca_temp = as.data.frame(pca_temp)
house_price3_pca = cbind(house_price3,pca_temp)
house_price3_pca$lat = NULL
house_price3_pca$long = NULL
house_train3_pca <- house_price3_pca[index,]
house_test3_pca <- house_price3_pca[-index,]
model_xgb_pca = train(price~.,data=house_train3_pca,
method = "xgbTree",trControl = kfolds,
tuneGrid = xgbGrid,na.action = na.pass,metric="MAE")
print(model_xgb_pca)
#### Prediction
val_xgb_pca <- predict(model_xgb_pca,house_test3_pca)
paste("MAPE: ", mape(real=house_test3_pca$price, predicted = val_xgb_pca)*100,"%",sep = '')
qplot(house_test3_pca$price, val_xgb_pca)
temp_price <-house_price3 %>%
select(price)
ggplot(temp_price,aes(x=price)) + geom_histogram(fill=HBarFillColor)
house_price3_logp <- house_price3
house_price3_logp$logprice <- log(house_price3_logp$price)
house_price3_logp$price <- NULL
house_train3_logp <- house_price3_logp[index,]
house_test3_logp <- house_price3_logp[-index,]
temp_price <-house_price3_logp %>%
select(logprice)
ggplot(temp_price,aes(x=logprice)) + geom_histogram(fill=HBarFillColor)
#RF - Log Price
model_rf_logp <- train(logprice~.,data=house_train3_logp, method="ranger",
num.trees=500,
preProc = NULL,
tuneGrid = tuneGrid,
trControl = kfolds,
metric = "MAE")
print(model_rf_logp)
# Prediction
val_rf_logp <- predict(model_rf_logp,house_test3_logp)
paste("MAPE: ", mape(real=exp(house_test3_logp$logprice),
predicted = exp(val_rf_logp))*100,"%",sep = '')
qplot(exp(house_test3_logp$logprice), exp(val_rf_logp))
# GBM - Log Price
model_gbm_logp <- train(logprice~.,data=house_train3_logp, method="gbm",
trControl = kfolds, verbose = F)
print(model_gbm_logp)
# Prediction
val_gbm_logp <- predict(model_gbm_logp,house_test3_logp)
paste("MAPE: ", mape(real=exp(house_test3_logp$logprice),
predicted = exp(val_gbm_logp))*100,"%",sep = '')
qplot(exp(house_test3_logp$logprice), exp(val_gbm_logp))
# XGB - Log Price
model_xgb_logp <- train(logprice~.,data=house_train3_logp, method="xgbTree", trControl=kfolds,
tuneGrid = xgbGrid, na.action = na.pass,
metric = "MAE")
print(model_xgb_logp)
# Import Test dataset
predict_set <- read.csv('input/house_price_test.csv', stringsAsFactor=F)
# Function for outlier treatment
outlier_treat <- function(train,test) {
x <- test
qnt <- quantile(train, probs=c(.25, .75), na.rm = T)
caps <- quantile(train, probs=c(.05, .95), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
x[x < (qnt[1] - H)] <- caps[1]
x[x > (qnt[2] + H)] <- caps[2]
return(x)
}
# Outlier treatment
predict_set$bedrooms_t <- outlier_treat(house_price$bedrooms, predict_set$bedrooms)
predict_set$bathrooms_t <- outlier_treat(house_price$bathrooms, predict_set$bathrooms)
predict_set$sqft_living_t <- outlier_treat(house_price$sqft_living, predict_set$sqft_living)
predict_set$sqft_lot_t <- outlier_treat(house_price$sqft_lot, predict_set$sqft_lot)
predict_set$grade_t <- outlier_treat(house_price$grade, predict_set$grade)
# New variables creation
predict_set$basement <- ifelse(predict_set$sqft_basement == 0, 0, 1)
predict_set$fview <- ifelse(predict_set$view == 0, 0, 1)
predict_set$renovated <- ifelse(predict_set$yr_renovated == 0, 0, 1)
predict_set$houseAge <- as.integer(format(Sys.Date(), "%Y")) - as.integer(as.character(predict_set$yr_built))
# Converting to Factor
fact <- c("fview","renovated", "basement", "waterfront")
predict_set[,fact] <- data.frame(apply(predict_set[fact], 2, as.factor))
# Numeric variable scalling
predict_set$grade_tf <-scale(predict_set$grade_t, center = mean(house_price1$grade_t),
scale = sd(house_price1$grade_t))
predict_set$sqft_living_tf <-scale(predict_set$sqft_living_t, center = mean(house_price1$sqft_living_t),
scale = sd(house_price1$sqft_living_t))
predict_set$sqft_lot_tf <-scale(predict_set$sqft_lot_t, center = mean(house_price1$sqft_lot_t),
scale = sd(house_price1$sqft_lot_t))
predict_set$houseAge_f <-scale(predict_set$houseAge, center = mean(house_price1$houseAge),
scale = sd(house_price1$houseAge))
predict_set$bedrooms_tf <-scale(predict_set$bedrooms_t, center = mean(house_price1$bedrooms_t),
scale = sd(house_price1$bedrooms_t))
predict_set$bathrooms_tf <-scale(predict_set$bathrooms_t, center = mean(house_price1$bathrooms_t),
scale = sd(house_price1$bathrooms_t))
predict_set$floors_f <-scale(predict_set$floors, center = mean(house_price1$floors),
scale = sd(house_price1$floors))
predict_set$condition_f <-scale(predict_set$condition, center = mean(house_price1$condition),
scale = sd(house_price1$condition))
# Keeping the required variables to run the model
keep <- c("id","grade_tf","sqft_living_tf","sqft_lot_tf","renovated",
"basement","houseAge_f","bathrooms_tf","bedrooms_tf","floors_f",
"waterfront","fview","lat", "long","condition_f")
predict_set2 <- predict_set[, (colnames(predict_set) %in% keep)]
# Predicting House prices on the new dataset
temp_pred <- predict_set2$id
predict_set2$id <- NULL
predict_set2$logpred <- predict(model_xgb_logp, newdata = predict_set2)
# Transform predictions from Log(Price) to Price
x <- data.frame(id = temp_pred)
x$pred_price <- exp(predict_set2$logpred)
# Export CSV
fwrite(x, "output/House_price_predictions.csv")
setwd("~/Documents/IE - MBD/3rd Term/Advanced R/Individual Assignment/Github")
# Import Test dataset
predict_set <- read.csv('input/house_price_test.csv', stringsAsFactor=F)
# Function for outlier treatment
outlier_treat <- function(train,test) {
x <- test
qnt <- quantile(train, probs=c(.25, .75), na.rm = T)
caps <- quantile(train, probs=c(.05, .95), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
x[x < (qnt[1] - H)] <- caps[1]
x[x > (qnt[2] + H)] <- caps[2]
return(x)
}
# Outlier treatment
predict_set$bedrooms_t <- outlier_treat(house_price$bedrooms, predict_set$bedrooms)
predict_set$bathrooms_t <- outlier_treat(house_price$bathrooms, predict_set$bathrooms)
predict_set$sqft_living_t <- outlier_treat(house_price$sqft_living, predict_set$sqft_living)
predict_set$sqft_lot_t <- outlier_treat(house_price$sqft_lot, predict_set$sqft_lot)
predict_set$grade_t <- outlier_treat(house_price$grade, predict_set$grade)
# New variables creation
predict_set$basement <- ifelse(predict_set$sqft_basement == 0, 0, 1)
predict_set$fview <- ifelse(predict_set$view == 0, 0, 1)
predict_set$renovated <- ifelse(predict_set$yr_renovated == 0, 0, 1)
predict_set$houseAge <- as.integer(format(Sys.Date(), "%Y")) - as.integer(as.character(predict_set$yr_built))
# Converting to Factor
fact <- c("fview","renovated", "basement", "waterfront")
predict_set[,fact] <- data.frame(apply(predict_set[fact], 2, as.factor))
# Numeric variable scalling
predict_set$grade_tf <-scale(predict_set$grade_t, center = mean(house_price1$grade_t),
scale = sd(house_price1$grade_t))
predict_set$sqft_living_tf <-scale(predict_set$sqft_living_t, center = mean(house_price1$sqft_living_t),
scale = sd(house_price1$sqft_living_t))
predict_set$sqft_lot_tf <-scale(predict_set$sqft_lot_t, center = mean(house_price1$sqft_lot_t),
scale = sd(house_price1$sqft_lot_t))
predict_set$houseAge_f <-scale(predict_set$houseAge, center = mean(house_price1$houseAge),
scale = sd(house_price1$houseAge))
predict_set$bedrooms_tf <-scale(predict_set$bedrooms_t, center = mean(house_price1$bedrooms_t),
scale = sd(house_price1$bedrooms_t))
predict_set$bathrooms_tf <-scale(predict_set$bathrooms_t, center = mean(house_price1$bathrooms_t),
scale = sd(house_price1$bathrooms_t))
predict_set$floors_f <-scale(predict_set$floors, center = mean(house_price1$floors),
scale = sd(house_price1$floors))
predict_set$condition_f <-scale(predict_set$condition, center = mean(house_price1$condition),
scale = sd(house_price1$condition))
# Keeping the required variables to run the model
keep <- c("id","grade_tf","sqft_living_tf","sqft_lot_tf","renovated",
"basement","houseAge_f","bathrooms_tf","bedrooms_tf","floors_f",
"waterfront","fview","lat", "long","condition_f")
predict_set2 <- predict_set[, (colnames(predict_set) %in% keep)]
# Predicting House prices on the new dataset
temp_pred <- predict_set2$id
predict_set2$id <- NULL
predict_set2$logpred <- predict(model_xgb_logp, newdata = predict_set2)
# Transform predictions from Log(Price) to Price
x <- data.frame(id = temp_pred)
x$pred_price <- exp(predict_set2$logpred)
# Export CSV
fwrite(x, "output/House_price_predictions.csv")
